{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3421918,"sourceType":"datasetVersion","datasetId":2062477},{"sourceId":10957109,"sourceType":"datasetVersion","datasetId":6816479},{"sourceId":11260652,"sourceType":"datasetVersion","datasetId":7037937}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine-tuning PaddleOCR's text detection models\n\nWe'll cover the following steps to fine-tune text detection models of PaddleOCR and to make inference with our fine-tuned model.\n\n1. Clone the PaddleOCR GitHub repository\n2. Install the framework PaddlePaddle, the gpu version\n3. Install the package PaddleOCR\n4. Get the data\n5. Get the pretrained model\n6. Train and evaluate the model\n7. Make inference on new images\n\n\nFirst, we need to clone the GitHub repository of PaddleOCR.","metadata":{}},{"cell_type":"markdown","source":"Next, we have to install the gpu version of PaddlePaddle, the core deep learning framework needed to run PaddleOCR. You may want consult the [PaddleOCR Quick Start](https://github.com/PaddlePaddle/PaddleOCR/blob/58e876d38d92b722f527946954c12231cd7ef7c6/doc/doc_en/quickstart_en.md). ","metadata":{}},{"cell_type":"code","source":"!python -m pip install -q paddlepaddle-gpu==2.5.0.post118 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html\n!pip install -q \"paddleocr>=2.0.1\" # Recommend to use version 2.0.1+\n!pip install -q imutils\n!pip install -q gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T07:30:41.690501Z","iopub.execute_input":"2025-04-03T07:30:41.690711Z","iopub.status.idle":"2025-04-03T07:32:24.895918Z","shell.execute_reply.started":"2025-04-03T07:30:41.690692Z","shell.execute_reply":"2025-04-03T07:32:24.894809Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.2/383.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m94.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"We're going to verify that our gpu paddle installation succeed with:","metadata":{}},{"cell_type":"code","source":"import paddle\ngpu_available  = paddle.device.is_compiled_with_cuda()\nprint(\"GPU available:\", gpu_available)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T07:49:39.639763Z","iopub.execute_input":"2025-04-03T07:49:39.640139Z","iopub.status.idle":"2025-04-03T07:49:42.360096Z","shell.execute_reply.started":"2025-04-03T07:49:39.640114Z","shell.execute_reply":"2025-04-03T07:49:42.359229Z"}},"outputs":[{"name":"stdout","text":"GPU available: True\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"paddle.utils.run_check()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T07:49:43.056179Z","iopub.execute_input":"2025-04-03T07:49:43.056589Z","iopub.status.idle":"2025-04-03T07:49:50.514951Z","shell.execute_reply.started":"2025-04-03T07:49:43.056562Z","shell.execute_reply":"2025-04-03T07:49:50.514245Z"}},"outputs":[{"name":"stdout","text":"Running verify PaddlePaddle program ... \nPaddlePaddle works well on 1 GPU.\nPaddlePaddle works well on 2 GPUs.\nPaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## The pretrained model\nPaddleOCR’s detection model supports 3 backbones (please refer to the [detection models documentation](https://github.com/PaddlePaddle/PaddleOCR/blob/main/doc/doc_en/detection_en.md)):\n1. MobileNetV3\n2. Resnet18_vd\n3. Resnet50_vd\n\nIt means that the model uses one of these architectures as a feature extractor, with layers trained to identify hierarchical patterns in images. \n\nThere are many algorithms of text detection included in PaddleOCR, for example, [DBNet](https://github.com/PaddlePaddle/PaddleOCR/blob/main/doc/doc_en/algorithm_det_db_en.md), [SAST](https://github.com/PaddlePaddle/PaddleOCR/blob/main/doc/doc_en/algorithm_det_sast_en.md), [EAST](https://github.com/PaddlePaddle/PaddleOCR/blob/main/doc/doc_en/algorithm_det_east_en.md), etc.\n\nWe'll employ the model  PP-OCRv3, regarded as the best model of PaddleOCR because of its precision and generalization capabilities, as mentioned on the [fine-tune](https://github.com/PaddlePaddle/PaddleOCR/blob/main/doc/doc_en/finetune_en.md) guide in the docs. \n\n* Download the .tar file from this [download link](https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_det_distill_train.tar).\n* Extract the files in the .tar file, where you'll find `student.pdparams`, which will served us as our pretrained model. \n\nThe next step is to get [the matching configuration file](https://github.com/PaddlePaddle/PaddleOCR/blob/main/configs/det/ch_PP-OCRv3/ch_PP-OCRv3_det_student.yml) for the student model.\n\n## The configuration file\n\nThis is going to be the configuration we will utilize with our pretrained model.","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/PaddlePaddle/PaddleOCR.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T07:49:54.486246Z","iopub.execute_input":"2025-04-03T07:49:54.486580Z","iopub.status.idle":"2025-04-03T07:50:44.226499Z","shell.execute_reply.started":"2025-04-03T07:49:54.486554Z","shell.execute_reply":"2025-04-03T07:50:44.224416Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'PaddleOCR'...\nremote: Enumerating objects: 138306, done.\u001b[K\nremote: Counting objects: 100% (9655/9655), done.\u001b[K\nremote: Compressing objects: 100% (1104/1104), done.\u001b[K\nremote: Total 138306 (delta 9202), reused 8713 (delta 8551), pack-reused 128651 (from 4)\u001b[K\nReceiving objects: 100% (138306/138306), 819.61 MiB | 37.00 MiB/s, done.\nResolving deltas: 100% (107872/107872), done.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"TXT = '''\nGlobal:\n  use_gpu: true\n  use_xpu: false\n  use_mlu: false\n  epoch_num: 50\n  log_smooth_window: 20\n  print_batch_step: 10\n  save_model_dir: ./output/db_mv3/\n  save_epoch_step: 50\n  # evaluation is run every 50 iterations\n  eval_batch_step: [0, 50]\n  cal_metric_during_train: False\n  pretrained_model: ./pretrain_models/MobileNetV3_large_x0_5_pretrained\n  checkpoints:\n  save_inference_dir:\n  use_visualdl: False\n  infer_img: doc/imgs_en/img_10.jpg\n  save_res_path: ./output/det_db/predicts_db.txt\n\nArchitecture:\n  model_type: det\n  algorithm: DB\n  Transform:\n  Backbone:\n    name: MobileNetV3\n    scale: 0.5\n    model_name: large\n  Neck:\n    name: DBFPN\n    out_channels: 256\n  Head:\n    name: DBHead\n    k: 50\n\nLoss:\n  name: DBLoss\n  balance_loss: true\n  main_loss_type: DiceLoss\n  alpha: 5\n  beta: 10\n  ohem_ratio: 3\n\nOptimizer:\n  name: Adam\n  beta1: 0.9\n  beta2: 0.999\n  lr:\n    learning_rate: 0.001\n  regularizer:\n    name: 'L2'\n    factor: 0\n\nPostProcess:\n  name: DBPostProcess\n  thresh: 0.3\n  box_thresh: 0.6\n  max_candidates: 1000\n  unclip_ratio: 1.5\n\nMetric:\n  name: DetMetric\n  main_indicator: hmean\n\nTrain:\n  dataset:\n    name: SimpleDataSet\n    data_dir: /kaggle/input/scalex5-plate\n    label_file_list:\n      - /kaggle/input/scalex5-plate/chi/Label.txt\n    ratio_list: [1.0]\n    transforms:\n      - DecodeImage: # load image\n          img_mode: BGR\n          channel_first: False\n      - DetLabelEncode: # Class handling label\n      - IaaAugment:\n          augmenter_args:\n            - { 'type': Fliplr, 'args': { 'p': 0.5 } }\n            - { 'type': Affine, 'args': { 'rotate': [-10, 10] } }\n            - { 'type': Resize, 'args': { 'size': [0.5, 3] } }\n      - EastRandomCropData:\n          size: [640, 640]\n          max_tries: 50\n          keep_ratio: true\n      - MakeBorderMap:\n          shrink_ratio: 0.4\n          thresh_min: 0.3\n          thresh_max: 0.7\n      - MakeShrinkMap:\n          shrink_ratio: 0.4\n          min_text_size: 8\n      - NormalizeImage:\n          scale: 1./255.\n          mean: [0.485, 0.456, 0.406]\n          std: [0.229, 0.224, 0.225]\n          order: 'hwc'\n      - ToCHWImage:\n      - KeepKeys:\n          keep_keys: ['image', 'threshold_map', 'threshold_mask', 'shrink_map', 'shrink_mask'] # the order of the dataloader list\n  loader:\n    shuffle: True\n    drop_last: False\n    batch_size_per_card: 16\n    num_workers: 8\n    use_shared_memory: True\n\nEval:\n  dataset:\n    name: SimpleDataSet\n    data_dir: /kaggle/input/scalex5-plate\n    label_file_list:\n      - /kaggle/input/scalex5-plate/chi/Label.txt\n    transforms:\n      - DecodeImage: # load image\n          img_mode: BGR\n          channel_first: False\n      - DetLabelEncode: # Class handling label\n      - DetResizeForTest:\n          image_shape: [736, 1280]\n      - NormalizeImage:\n          scale: 1./255.\n          mean: [0.485, 0.456, 0.406]\n          std: [0.229, 0.224, 0.225]\n          order: 'hwc'\n      - ToCHWImage:\n      - KeepKeys:\n          keep_keys: ['image', 'shape', 'polys', 'ignore_tags']\n  loader:\n    shuffle: False\n    drop_last: False\n    batch_size_per_card: 1 # must be 1\n    num_workers: 8\n    use_shared_memory: True\n\n'''\nPATH_TXT = \"/kaggle/working/config.yml\"\n\nwith open(PATH_TXT, 'w', encoding = \"utf-8\") as f:\n    f.write(TXT)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T07:54:44.404711Z","iopub.execute_input":"2025-04-03T07:54:44.405051Z","iopub.status.idle":"2025-04-03T07:54:44.411315Z","shell.execute_reply.started":"2025-04-03T07:54:44.405027Z","shell.execute_reply":"2025-04-03T07:54:44.410567Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"cd /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T08:01:31.834205Z","iopub.execute_input":"2025-04-03T08:01:31.834562Z","iopub.status.idle":"2025-04-03T08:01:31.839921Z","shell.execute_reply.started":"2025-04-03T08:01:31.834537Z","shell.execute_reply":"2025-04-03T08:01:31.839063Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!cat /kaggle/working/config.yml","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Some of the information that `config.yml` contains is: \n\n* Hyperparameters. The most importants are: `pretrained_model`, `batch_size`, and `learning_rate`.\n    * For a single gpu:\n        * batch_size = 8\n        * learning_rate = 1e-4\n    * For a single gpu with memory limitations:\n        * batch_size = 4\n        * learning_rate = 5e-5\n* The paths of our images and annotations.\n* The algorithm and backbone. ","metadata":{}},{"cell_type":"code","source":"!pip install pyyaml","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import yaml\n\n# Load the YAML file\nwith open('/kaggle/working/config.yml', 'r') as file:\n    data = yaml.safe_load(file)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f'pretrained model: {data[\"Global\"][\"pretrained_model\"]}')\nprint(f'number of epochs: {data[\"Global\"][\"epoch_num\"]}')\nprint(f'evaluate every: {data[\"Global\"][\"eval_batch_step\"][1]} iterations')\nprint(f'learning rate: {data[\"Optimizer\"][\"lr\"][\"learning_rate\"]}')\nprint(f'training batch size: {data[\"Train\"][\"loader\"][\"batch_size_per_card\"]}')\nprint(f'training images path: {data[\"Train\"][\"dataset\"][\"data_dir\"]}')\nprint(f'training annotations file path: {data[\"Train\"][\"dataset\"][\"label_file_list\"]}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training and evaluation\n\nWe'll make use of the Kaggle's `GPU T4 x 2`,  so we'll perform a multi-gpu training with the following command. For more details, refer to the [documentation](https://github.com/PaddlePaddle/PaddleOCR/blob/main/doc/doc_en/detection_en.md).\n\nThe model's evaluation will be carried out every `400` iterations as was specified in `config[\"Global\"][\"eval_batch_step\"]`.\n\n### Metrics\nFor the evaluation, the detection model returns hmean as the main metric, and also computes precision and recall, as you can confirm [here](https://github.com/PaddlePaddle/PaddleOCR/blob/58e876d38d92b722f527946954c12231cd7ef7c6/ppocr/metrics/det_metric.py).\n","metadata":{}},{"cell_type":"code","source":"!cd /kaggle/working/PaddleOCR\n# Download the pre-trained model of MobileNetV3\n!wget -P ./pretrain_models/ https://paddleocr.bj.bcebos.com/pretrained/MobileNetV3_large_x0_5_pretrained.pdparams\n# or, download the pre-trained model of ResNet18_vd\n!wget -P ./pretrain_models/ https://paddleocr.bj.bcebos.com/pretrained/ResNet18_vd_pretrained.pdparams\n# or, download the pre-trained model of ResNet50_vd\n!wget -P ./pretrain_models/ https://paddleocr.bj.bcebos.com/pretrained/ResNet50_vd_ssld_pretrained.pdparams\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cd ./PaddleOCR","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T08:01:37.876611Z","iopub.execute_input":"2025-04-03T08:01:37.876920Z","iopub.status.idle":"2025-04-03T08:01:37.886746Z","shell.execute_reply.started":"2025-04-03T08:01:37.876895Z","shell.execute_reply":"2025-04-03T08:01:37.886014Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/PaddleOCR\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!python tools/infer_det.py -c /kaggle/working/config.yml -o Global.infer_img=\"/kaggle/input/scalex5-plate/chi/crop_plate_957.jpg\" Global.pretrained_model=\"/kaggle/working/pretrain_models/MobileNetV3_large_x0_5_pretrained.pdparams\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cat /kaggle/working/PaddleOCR/output/det_db/predicts_db.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python tools/train.py -c /kaggle/working/config.yml -o Global.pretrained_model=\"./pretrain_models/MobileNetV3_large_x0_5_pretrained\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python tools/export_model.py -c /kaggle/working/config.yml -o Global.pretrained_model=\"/kaggle/input/det-best-model/best_model/best_model.pdparams\" Global.save_inference_dir=\"./inference/det_db_inference/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T08:04:29.090072Z","iopub.execute_input":"2025-04-03T08:04:29.090431Z","iopub.status.idle":"2025-04-03T08:04:34.830071Z","shell.execute_reply.started":"2025-04-03T08:04:29.090402Z","shell.execute_reply":"2025-04-03T08:04:34.829247Z"}},"outputs":[{"name":"stdout","text":"[2025/04/03 08:04:30] ppocr WARNING: Skipping import of the encryption module.\nW0403 08:04:31.192308   197 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.6, Runtime API Version: 11.8\nW0403 08:04:31.193373   197 gpu_resources.cc:149] device: 0, cuDNN Version: 8.9.\n[2025/04/03 08:04:31] ppocr INFO: load pretrain successful from /kaggle/input/det-best-model/best_model/best_model\n[2025/04/03 08:04:31] ppocr INFO: Export inference config file to ./inference/det_db_inference/inference.yml\nSkipping import of the encryption module\nI0403 08:04:33.830382   197 interpretercore.cc:237] New Executor is Running.\n[2025/04/03 08:04:34] ppocr INFO: inference model is saved to ./inference/det_db_inference/inference\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!python3 tools/infer_det.py -c /kaggle/working/config.yml \\\n  -o Global.pretrained_model=\"./output/db_mv3/best_accuracy\" \\\n     Global.infer_img=\"/kaggle/input/scalex5-plate/chi/crop_plate_1036.jpg\"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python tools/infer/predict_det.py --det_algorithm=\"DB\" --det_model_dir=\"./inference/det_db_inference/\" --image_dir=\"/kaggle/input/scalex5-plate/chi/crop_plate_1036.jpg\" --use_gpu=True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cat /kaggle/working/PaddleOCR/inference_results/det_results.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Đọc ảnh test\nimg_path = \"/kaggle/working/PaddleOCR/output/det_db/det_results/crop_plate_1036.jpg\"\nimage = cv2.imread(img_path)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Đọc file kết quả inference (nếu có)\nresult_json_path = \"/kaggle/working/PaddleOCR/output/det_db/predicts_db.txt\"\n\n# Kiểm tra nếu file kết quả tồn tại\ntry:\n    with open(result_json_path, \"r\") as f:\n        results = f.readlines()\n\n    # Tìm kết quả của ảnh đang test\n    detected_boxes = []\n    for line in results:\n        if img_path in line:\n            parts = line.strip().split(\"\\t\")\n            if len(parts) > 1:\n                detected_boxes = json.loads(parts[1])  # Chuyển đổi từ JSON\n            break\n\n    # Vẽ bounding box nếu có object được phát hiện\n    if detected_boxes:\n        for box in detected_boxes:\n            points = np.array(box[\"points\"], np.int32).reshape((-1, 1, 2))\n            cv2.polylines(image, [points], isClosed=True, color=(255, 0, 0), thickness=2)  # Màu đỏ\n\n    # Hiển thị ảnh\n    plt.figure(figsize=(8, 8))\n    plt.imshow(image)\n    plt.axis(\"off\")\n    plt.show()\n\nexcept Exception as e:\n    print(\"Lỗi khi đọc file kết quả:\", e)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}